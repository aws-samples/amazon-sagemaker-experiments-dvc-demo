{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a CatBoost regression model with data from DVC\n",
    "\n",
    "With Amazon SageMaker, you can package your own algorithms that can than be trained and deployed in the SageMaker environment. This notebook will guide you through an example that shows you how to build a Docker container for SageMaker and use it for training and inference.\n",
    "\n",
    "By packaging an algorithm in a container, you can bring almost any code to the Amazon SageMaker environment, regardless of programming language, environment, framework, or dependencies. \n",
    "\n",
    "### California Housing dataset\n",
    "We use the California Housing dataset, present in [Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html). \n",
    "\n",
    "The California Housing dataset was originally published in:\n",
    "\n",
    "Pace, R. Kelley, and Ronald Barry. \"Sparse spatial auto-regressions.\" Statistics & Probability Letters 33.3 (1997): 291-297.\n",
    "\n",
    "\n",
    "### DVC\n",
    "DVC is built to make ML models shareable and reproducible. It is designed to handle large files, data sets, machine learning models, and metrics as well as code.\n",
    "\n",
    "[DVC Official Site](https://dvc.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Packaging and Uploading your Algorithm for use with Amazon SageMaker\n",
    "\n",
    "### An overview of Docker\n",
    "\n",
    "If you're familiar with Docker already, you can skip ahead to the next section.\n",
    "\n",
    "For many data scientists, Docker containers are a new concept, but they are not difficult, as you'll see here. \n",
    "\n",
    "Docker provides a simple way to package arbitrary code into an _image_ that is totally self-contained. Once you have an image, you can use Docker to run a _container_ based on that image. Running a container is just like running a program on the machine except that the container creates a fully self-contained environment for the program to run. Containers are isolated from each other and from the host environment, so the way you set up your program is the way it runs, no matter where you run it.\n",
    "\n",
    "Docker is more powerful than environment managers like conda or virtualenv because (a) it is completely language independent and (b) it comprises your whole operating environment, including startup commands, environment variable, etc.\n",
    "\n",
    "In some ways, a Docker container is like a virtual machine, but it is much lighter weight. For example, a program running in a container can start in less than a second and many containers can run on the same physical machine or virtual machine instance.\n",
    "\n",
    "Docker uses a simple file called a `Dockerfile` to specify how the image is assembled. We'll see an example of that below. You can build your Docker images based on Docker images built by yourself or others, which can simplify things quite a bit.\n",
    "\n",
    "Docker has become very popular in the programming and devops communities for its flexibility and well-defined specification of the code to be run. It is the underpinning of many services built in the past few years, such as [Amazon ECS].\n",
    "\n",
    "Amazon SageMaker uses Docker to allow users to train and deploy arbitrary algorithms.\n",
    "\n",
    "In Amazon SageMaker, Docker containers are invoked in a certain way for training and a slightly different way for hosting. The following sections outline how to build containers for the SageMaker environment.\n",
    "\n",
    "Some helpful links:\n",
    "\n",
    "* [Docker home page](http://www.docker.com)\n",
    "* [Getting started with Docker](https://docs.docker.com/get-started/)\n",
    "* [Dockerfile reference](https://docs.docker.com/engine/reference/builder/)\n",
    "* [`docker run` reference](https://docs.docker.com/engine/reference/run/)\n",
    "\n",
    "[Amazon ECS]: https://aws.amazon.com/ecs/\n",
    "\n",
    "### How Amazon SageMaker runs your Docker container\n",
    "\n",
    "Because you can run the same image in training or hosting, Amazon SageMaker runs your container with the argument `train` or `serve`. How your container processes this argument depends on the container:\n",
    "\n",
    "* In the example here, we don't define an `ENTRYPOINT` in the Dockerfile so Docker will run the command `train` at training time and `serve` at serving time. In this example, we define these as executable Python scripts, but they could be any program that we want to start in that environment.\n",
    "* If you specify a program as an `ENTRYPOINT` in the Dockerfile, that program will be run at startup and its first argument will be `train` or `serve`. The program can then look at that argument and decide what to do.\n",
    "* If you are building separate containers for training and hosting (or building only for one or the other), you can define a program as an `ENTRYPOINT` in the Dockerfile and ignore (or verify) the first argument passed in. \n",
    "\n",
    "#### Running your container during training\n",
    "\n",
    "When Amazon SageMaker runs training, your `train` script is run just like a regular Python program. A number of files are laid out for your use, under the `/opt/ml` directory:\n",
    "\n",
    "    /opt/ml\n",
    "    |-- input\n",
    "    |   |-- config\n",
    "    |   |   |-- hyperparameters.json\n",
    "    |   |   `-- resourceConfig.json\n",
    "    |   `-- data\n",
    "    |       `-- <channel_name>\n",
    "    |           `-- <input data>\n",
    "    |-- model\n",
    "    |   `-- <model files>\n",
    "    `-- output\n",
    "        `-- failure\n",
    "\n",
    "##### The input\n",
    "\n",
    "* `/opt/ml/input/config` contains information to control how your program runs. `hyperparameters.json` is a JSON-formatted dictionary of hyperparameter names to values. These values will always be strings, so you may need to convert them. `resourceConfig.json` is a JSON-formatted file that describes the network layout used for distributed training. Since scikit-learn doesn't support distributed training, we'll ignore it here.\n",
    "* `/opt/ml/input/data/<channel_name>/` (for File mode) contains the input data for that channel. The channels are created based on the call to CreateTrainingJob but it's generally important that channels match what the algorithm expects. The files for each channel will be copied from S3 to this directory, preserving the tree structure indicated by the S3 key structure. \n",
    "* `/opt/ml/input/data/<channel_name>_<epoch_number>` (for Pipe mode) is the pipe for a given epoch. Epochs start at zero and go up by one each time you read them. There is no limit to the number of epochs that you can run, but you must close each pipe before reading the next epoch.\n",
    "\n",
    "##### The output\n",
    "\n",
    "* `/opt/ml/model/` is the directory where you write the model that your algorithm generates. Your model can be in any format that you want. It can be a single file or a whole directory tree. SageMaker will package any files in this directory into a compressed tar archive file. This file will be available at the S3 location returned in the `DescribeTrainingJob` result.\n",
    "* `/opt/ml/output` is a directory where the algorithm can write a file `failure` that describes why the job failed. The contents of this file will be returned in the `FailureReason` field of the `DescribeTrainingJob` result. For jobs that succeed, there is no reason to write this file as it will be ignored.\n",
    "\n",
    "#### Running your container during hosting\n",
    "\n",
    "Hosting has a very different model than training because hosting is responding to inference requests that come in via HTTP. In this example, we use our recommended Python serving stack to provide robust and scalable serving of inference requests:\n",
    "\n",
    "![Request serving stack](stack.png)\n",
    "\n",
    "This stack is implemented in the sample code here and you can mostly just leave it alone. \n",
    "\n",
    "Amazon SageMaker uses two URLs in the container:\n",
    "\n",
    "* `/ping` will receive `GET` requests from the infrastructure. Your program returns 200 if the container is up and accepting requests.\n",
    "* `/invocations` is the endpoint that receives client inference `POST` requests. The format of the request and the response is up to the algorithm. If the client supplied `ContentType` and `Accept` headers, these will be passed in as well. \n",
    "\n",
    "The container will have the model files in the same place they were written during training:\n",
    "\n",
    "    /opt/ml\n",
    "    `-- model\n",
    "        `-- <model files>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parts of the sample container\n",
    "\n",
    "In the `container` directory are all the components you need to package the sample algorithm for Amazon SageMager:\n",
    "\n",
    "    .\n",
    "    |-- Dockerfile\n",
    "    `-- catboost_regressor\n",
    "        |-- nginx.conf\n",
    "        |-- predictor.py\n",
    "        |-- serve\n",
    "        |-- train\n",
    "        `-- wsgi.py\n",
    "\n",
    "Let's discuss each of these in turn:\n",
    "\n",
    "* __`Dockerfile`__ describes how to build your Docker container image. More details below.\n",
    "* __`catboost_regressor`__ is the directory which contains the files that will be installed in the container.\n",
    "* __`local_test`__ is a directory that shows how to test your new container on any computer that can run Docker, including an Amazon SageMaker notebook instance. Using this method, you can quickly iterate using small datasets to eliminate any structural bugs before you use the container with Amazon SageMaker. We'll walk through local testing later in this notebook.\n",
    "\n",
    "In this simple application, we only install five files in the container. You may only need that many or, if you have many supporting routines, you may wish to install more. These five show the standard structure of our Python containers, although you are free to choose a different toolset and therefore could have a different layout. If you're writing in a different programming language, you'll certainly have a different layout depending on the frameworks and tools you choose.\n",
    "\n",
    "The files that we'll put in the container are:\n",
    "\n",
    "* __`nginx.conf`__ is the configuration file for the nginx front-end. Generally, you should be able to take this file as-is.\n",
    "* __`predictor.py`__ is the program that actually implements the Flask web server and the decision tree predictions for this app. You'll want to customize the actual prediction parts to your application. Since this algorithm is simple, we do all the processing here in this file, but you may choose to have separate files for implementing your custom logic.\n",
    "* __`serve`__ is the program started when the container is started for hosting. It simply launches the gunicorn server which runs multiple instances of the Flask app defined in `predictor.py`. You should be able to take this file as-is.\n",
    "* __`train`__ is the program that is invoked when the container is run for training. You will modify this program to implement your training algorithm.\n",
    "* __`wsgi.py`__ is a small wrapper used to invoke the Flask app. You should be able to take this file as-is.\n",
    "\n",
    "In summary, the two files you will probably want to change for your application are `train` and `predictor.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Build an image that can do training and inference in SageMaker\n",
      "# This is a Python 3 image that uses the nginx, gunicorn, flask stack\n",
      "# for serving inferences in a stable way.\n",
      "\n",
      "FROM public.ecr.aws/docker/library/python:3.7-slim\n",
      "\n",
      "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\n",
      "         wget \\\n",
      "         nginx \\\n",
      "         git \\\n",
      "         ca-certificates\n",
      "\n",
      "RUN pip install numpy==1.16.2 scipy==1.2.1 catboost pandas flask gevent gunicorn\n",
      "RUN pip install dvc==2.8.3 s3fs==2021.10.1 dvc-s3==2.8.3\n",
      "RUN pip install awscli boto3\n",
      "RUN pip install git-remote-codecommit\n",
      "\n",
      "# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard\n",
      "# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE\n",
      "# keeps Python from writing the .pyc files which are unnecessary in this case. We also update\n",
      "# PATH so that the train and serve programs are found when the container is invoked.\n",
      "\n",
      "ENV PYTHONUNBUFFERED=TRUE\n",
      "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      "ENV PATH=\"/opt/program:${PATH}\"\n",
      "\n",
      "# Set up the program in the image\n",
      "COPY catboost_regressor /opt/program\n",
      "WORKDIR /opt/program\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `container` directory are all the components you need to package the sample algorithm for Amazon SageMaker:\n",
    "\n",
    "    .\n",
    "    `-- container/\n",
    "        |-- Dockerfile\n",
    "        |-- README.md\n",
    "        `--catboost_regressor/\n",
    "            |-- nginx.conf\n",
    "            |-- predictor.py\n",
    "            |-- serve\n",
    "            |-- train\n",
    "            |-- wsgi.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and registering the container\n",
    "\n",
    "TODO: explain what we are doing here and the `sm-docker` build command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-catboost-dvc\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x catboost_regressor/train\n",
    "chmod +x catboost_regressor/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-1 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-eu-west-1}\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "sm-docker build . --repository \"${algorithm_name}:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure DVC for data versioning\n",
    "\n",
    "Let us create a subdirectory where we prepare the data, i.e. `sagemaker-dvc-sample`.\n",
    "Within this subdirectory, we initialize a new git repository and set the remote to a repository we create in AWS CodeCommit.\n",
    "Finally, the `dvc` configurations and files for data tracking will be versioned in this repository.\n",
    "\n",
    "One of the advantage of using AWS CodeCommit is its integration with IAM for authentication purposes, meaning we can use IAM roles to push / pull data without the need to fetch credentials or ssh keys. Setting the appropriate permissions on SageMaker execution role will also allow the SageMaker training job to interact securely with the AWS CodeCommit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "## Create the repository\n",
    "\n",
    "repo_name=\"sagemaker-dvc-sample\"\n",
    "\n",
    "aws codecommit create-repository --repository-name ${repo_name} --repository-description \"Sample repository to describe how to use dvc with sagemaker and codecommit\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to eu-west-1 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-eu-west-1}\n",
    "\n",
    "## repo_name is already in the .gitignore of the root repo\n",
    "\n",
    "mkdir -p ${repo_name}\n",
    "cd ${repo_name}\n",
    "\n",
    "# initalize new repo in subfolder\n",
    "git init\n",
    "## Change the remote to the codecommit\n",
    "git remote add origin https://git-codecommit.\"${region}\".amazonaws.com/v1/repos/\"${repo_name}\"\n",
    "\n",
    "# Configure git\n",
    "git config --global user.email \"you@example.com\"\n",
    "git config --global user.name \"Your Name\"\n",
    "\n",
    "git config --global credential.helper '!aws codecommit credential-helper $@'\n",
    "git config --global credential.UseHttpPath true\n",
    "\n",
    "# Initialize dvc\n",
    "dvc init\n",
    "\n",
    "git commit -m 'Add dvc configuration'\n",
    "\n",
    "# Set the DVC remote storage to S3\n",
    "dvc remote add -d storage s3://sagemaker-\"${region}\"-\"${account}\"/DEMO-sagemaker-experiments-dvc\n",
    "git commit .dvc/config -m \"initialize DVC local remote\"\n",
    "\n",
    "# set the DVC cache to S3\n",
    "dvc remote add s3cache s3://sagemaker-\"${region}\"-\"${account}\"/DEMO-sagemaker-experiments-dvc/cache\n",
    "dvc config cache.s3 s3cache\n",
    "\n",
    "# disable sending anonymized data to dvc for troubleshooting\n",
    "dvc config core.analytics false\n",
    "\n",
    "git add .dvc/config\n",
    "git commit -m 'update dvc config'\n",
    "\n",
    "git push --set-upstream origin master --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account: 583558296381\n",
      "bucket: sagemaker-eu-west-1-583558296381\n",
      "region: eu-west-1\n",
      "role: arn:aws:iam::583558296381:role/RoleSagemakerStudioUsers\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "from time import strftime\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "region = boto_session.region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "account = sagemaker_session.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "\n",
    "prefix = 'DEMO-sagemaker-experiments-dvc'\n",
    "\n",
    "print(f\"account: {account}\")\n",
    "print(f\"bucket: {bucket}\")\n",
    "print(f\"region: {region}\")\n",
    "print(f\"role: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare raw data\n",
    "\n",
    "Send the raw data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape = (20640, 9)\n",
      "s3://sagemaker-eu-west-1-583558296381/DEMO-sagemaker-experiments-dvc/input/dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "databunch = fetch_california_housing()\n",
    "dataset = np.concatenate((databunch[\"target\"].reshape(-1, 1), databunch[\"data\"]), axis=1)\n",
    "\n",
    "print(f\"Dataset shape = {dataset.shape}\")\n",
    "np.savetxt(\"dataset.csv\", dataset, delimiter=\",\")\n",
    "\n",
    "data_prefix_path = f\"{prefix}/input/dataset.csv\"\n",
    "s3_data_path = f\"s3://{bucket}/{data_prefix_path}\"\n",
    "print(f\"Raw data location in S3: {s3_data_path}\")\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.upload_file(\"dataset.csv\", bucket, data_prefix_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Experiments\n",
    "\n",
    "Now, in order to track this test in Sagemaker, we need to create an experiment. We need to also define the trial within the experiment. For the sake of simplicity, we just consider one trial for the experiment, but we can have any number of trials within an experiment, for example if you want to test different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "experiment_name = 'DEMO-sagemaker-experiments-dvc'\n",
    "\n",
    "# create the experiment if it doesn't exist\n",
    "try:\n",
    "    my_experiment = Experiment.load(experiment_name=experiment_name)\n",
    "    print(\"existing experiment loaded\")\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        my_experiment = Experiment.create(\n",
    "            experiment_name = experiment_name,\n",
    "            description = \"How to integrate DVC\"\n",
    "        )\n",
    "        print(\"new experiment created\")\n",
    "    else:\n",
    "        print(f\"Unexpected {ex}=, {type(ex)}\")\n",
    "        print(\"Dont go forward!\")\n",
    "        raise\n",
    "\n",
    "first_trial_name = \"dvc-trial-v1\"\n",
    "\n",
    "try:\n",
    "    my_first_trial = Trial.load(trial_name=first_trial_name)\n",
    "    print(\"existing trial loaded\")\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        my_first_trial = Trial.create(\n",
    "            experiment_name=experiment_name,\n",
    "            trial_name=first_trial_name,\n",
    "        )\n",
    "        print(\"new trial created\")\n",
    "    else:\n",
    "        print(f\"Unexpected {ex}=, {type(ex)}\")\n",
    "        print(\"Dont go forward!\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare processing job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version data with DVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODOs: install `dvc` related libraries within the script using `subprocess` calls (quick and dirty), or create a processing container where we have everything installed, possibly also configured (takes longer, but more elegant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing-experiment-1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing-experiment-1.py\n",
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: MIT-0\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read data locally\n",
    "input_data_path = os.path.join(\"/opt/ml/processing/input\", \"dataset.csv\")\n",
    "\n",
    "prefix = '/opt/ml/'\n",
    "input_path = prefix + 'processing/input'\n",
    "dataset_path = prefix + input_path\n",
    "train_channel_name = 'train'\n",
    "validation_channel_name = 'validation'\n",
    "base_dir = './sagemaker-dvc-sample/dataset'\n",
    "\n",
    "train_path = os.path.join(dataset_path, train_channel_name)\n",
    "validation_path = os.path.join(dataset_path, validation_channel_name)\n",
    "\n",
    "#my_tracker = tracker.Tracker.load()\n",
    "\n",
    "def clone_dvc_git_repo(dvc_repo_url):\n",
    "    print(f\"Configure git to pull authenticated from CodeCommit\")\n",
    "    print(f\"Cloning repo: {dvc_repo_url}\")\n",
    "    subprocess.check_call([\"git\", \"clone\", dvc_repo_url])\n",
    "\n",
    "def install_dependencies():\n",
    "    print(\"Install git-remote-codecommit and sagemaker-experiments\")\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-Uq', 'git-remote-codecommit'])\n",
    "    print(\"Install DVC and drivers for S3\")\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-Uq', 'dvc==2.8.3', 's3fs==2021.10.1'])\n",
    "    print(\"dependencies installed successfully\")\n",
    "\n",
    "def configure_git():\n",
    "    print(\"Configure git\")\n",
    "    subprocess.check_call(['git', 'config', '--global', 'user.email', 'sagemaker-processing@example.com'])\n",
    "    subprocess.check_call(['git', 'config', '--global', 'user.name', 'SageMaker Processing Job'])\n",
    "\n",
    "def generate_train_validation_files(ratio):\n",
    "    for path in ['train', 'validation', 'test']:\n",
    "        output_dir = Path(f\"{base_dir}/{path}/\")\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"Read dataset\")\n",
    "    dataset = pd.read_csv(input_data_path)\n",
    "    train, other = train_test_split(dataset, test_size=ratio)\n",
    "    validation, test = train_test_split(other, test_size=ratio)\n",
    "    \n",
    "    print(\"create train, validation, test\")\n",
    "    pd.DataFrame(train).to_csv(f\"{base_dir}/train/california_train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(f\"{base_dir}/validation/california_validation.csv\", header=False, index=False)\n",
    "    pd.DataFrame(test).to_csv(f\"{base_dir}/test/california_test.csv\", header=False, index=False)\n",
    "    print(\"data created\")\n",
    "\n",
    "def sync_data_with_dvc(branch):\n",
    "    os.chdir(base_dir)\n",
    "    print(f\"Create branch {branch}\")\n",
    "    try:\n",
    "        subprocess.check_call(['git', 'checkout', '-b', branch])\n",
    "        print(f\"Create a new branch: {branch}\")\n",
    "    except:\n",
    "        subprocess.check_call(['git', 'checkout', branch])\n",
    "        print(f\"Checkout existing branch: {branch}\")\n",
    "    print(\"Add files to DVC\")\n",
    "    subprocess.check_call(['dvc', 'add', 'train/california_train.csv'])\n",
    "    subprocess.check_call(['dvc', 'add', 'validation/california_validation.csv'])\n",
    "    subprocess.check_call(['dvc', 'add', 'test/california_test.csv'])\n",
    "    subprocess.check_call(['git', 'add', '.'])\n",
    "    subprocess.check_call(['git', 'commit', '-m', f\"'add data for {branch}'\"])\n",
    "    print(\"Push data to DVC\")\n",
    "    subprocess.check_call(['dvc', 'push'])\n",
    "    print(\"Push dvc metadata to git\")\n",
    "    subprocess.check_call(['git', 'push', '--set-upstream', 'origin', branch, '--force'])\n",
    "    commit_hash = subprocess.check_output(['git', 'log', '--format=%H', '-n', '1']).decode(\"utf-8\").replace('\\n','')\n",
    "    #my_tracker.log_parameters({\"data_commit_hash\": commit_hash})\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    print(parser)\n",
    "    parser.add_argument(\"--train-test-split-ratio\", type=float, default=0.3)\n",
    "    parser.add_argument(\"--dvc-repo-url\", type=str, default=\"codecommit::eu-west-1://sagemaker-dvc-sample\")\n",
    "    parser.add_argument(\"--dvc-tag\", type=str, default=\"v1.0.0\")\n",
    "    parser.add_argument(\"--dvc-branch\", type=str, default=\"experiment-1\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    install_dependencies()\n",
    "    configure_git()\n",
    "    clone_dvc_git_repo(args.dvc_repo_url)\n",
    "    generate_train_validation_files(args.train_test_split_ratio)\n",
    "    sync_data_with_dvc(args.dvc_branch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvc_repo_url = \"codecommit::{}://sagemaker-dvc-sample\".format(region)\n",
    "dvc_tag = \"v1.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create processing container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM public.ecr.aws/docker/library/python:3.7-slim\n",
      "\n",
      "RUN apt-get -y update && apt-get install -y --no-install-recommends wget git\n",
      "\n",
      "RUN pip3 install numpy pandas scikit-learn==1.0.2\n",
      "RUN pip install awscli==1.22.67 boto3==1.21.12\n",
      "RUN pip3 install sagemaker==2.77.1 sagemaker-experiments==0.1.35\n",
      "RUN pip3 install git-remote-codecommit\n",
      "RUN pip3 install dvc==2.8.3 s3fs==2021.10.1\n",
      "\n",
      "RUN pip3 install git-remote-codecommit sagemaker-experiments\n",
      "\n",
      "# Configure git\n",
      "\n",
      "RUN git config --global user.email \"sagemaker-processing@example.com\"\n",
      "RUN git config --global user.name \"SageMaker ProcessingJob User\"\n",
      "\n",
      "ENV PYTHONUNBUFFERED=TRUE\n",
      "\n",
      "ENTRYPOINT [\"python3\"]\n"
     ]
    }
   ],
   "source": [
    "!cat container/processing/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...[Container] 2022/03/08 21:44:37 Waiting for agent ping\n",
      "\n",
      "[Container] 2022/03/08 21:44:38 Waiting for DOWNLOAD_SOURCE\n",
      "[Container] 2022/03/08 21:44:40 Phase is DOWNLOAD_SOURCE\n",
      "[Container] 2022/03/08 21:44:40 CODEBUILD_SRC_DIR=/codebuild/output/src205974770/src\n",
      "[Container] 2022/03/08 21:44:40 YAML location is /codebuild/output/src205974770/src/buildspec.yml\n",
      "[Container] 2022/03/08 21:44:40 Setting HTTP client timeout to higher timeout for S3 source\n",
      "[Container] 2022/03/08 21:44:40 Processing environment variables\n",
      "[Container] 2022/03/08 21:44:40 No runtime version selected in buildspec.\n",
      "[Container] 2022/03/08 21:44:40 Moving to directory /codebuild/output/src205974770/src\n",
      "[Container] 2022/03/08 21:44:40 Configuring ssm agent with target id: codebuild:79af8537-ab9c-41eb-88ec-6a4806d0fca0\n",
      "[Container] 2022/03/08 21:44:40 Successfully updated ssm agent configuration\n",
      "[Container] 2022/03/08 21:44:40 Registering with agent\n",
      "[Container] 2022/03/08 21:44:40 Phases found in YAML: 3\n",
      "[Container] 2022/03/08 21:44:40  PRE_BUILD: 9 commands\n",
      "[Container] 2022/03/08 21:44:40  BUILD: 4 commands\n",
      "[Container] 2022/03/08 21:44:40  POST_BUILD: 3 commands\n",
      "[Container] 2022/03/08 21:44:40 Phase complete: DOWNLOAD_SOURCE State: SUCCEEDED\n",
      "[Container] 2022/03/08 21:44:40 Phase context status code:  Message:\n",
      "[Container] 2022/03/08 21:44:40 Entering phase INSTALL\n",
      "[Container] 2022/03/08 21:44:40 Phase complete: INSTALL State: SUCCEEDED\n",
      "[Container] 2022/03/08 21:44:40 Phase context status code:  Message:\n",
      "[Container] 2022/03/08 21:44:40 Entering phase PRE_BUILD\n",
      "[Container] 2022/03/08 21:44:40 Running command echo Logging in to Amazon ECR...\n",
      "Logging in to Amazon ECR...\n",
      "\n",
      "[Container] 2022/03/08 21:44:40 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/03/08 21:44:45 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 763104351884)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/03/08 21:44:46 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 217643126080)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/03/08 21:44:46 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 727897471807)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/03/08 21:44:47 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 626614931356)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/03/08 21:44:47 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 683313688378)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/03/08 21:44:47 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 520713654638)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/03/08 21:44:48 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 462105765813)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/03/08 21:44:48 Phase complete: PRE_BUILD State: SUCCEEDED\n",
      "[Container] 2022/03/08 21:44:48 Phase context status code:  Message:\n",
      "[Container] 2022/03/08 21:44:48 Entering phase BUILD\n",
      "[Container] 2022/03/08 21:44:48 Running command echo Build started on `date`\n",
      "Build started on Tue Mar 8 21:44:48 UTC 2022\n",
      "\n",
      "[Container] 2022/03/08 21:44:48 Running command echo Building the Docker image...\n",
      "Building the Docker image...\n",
      "\n",
      "[Container] 2022/03/08 21:44:48 Running command docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
      "Sending build context to Docker daemon  6.144kB\n",
      "Step 1/12 : FROM public.ecr.aws/docker/library/python:3.7-slim\n",
      "3.7-slim: Pulling from docker/library/python\n",
      "f7a1c6dad281: Pulling fs layer\n",
      "92c59ec44e08: Pulling fs layer\n",
      "20ca33a0aa64: Pulling fs layer\n",
      "15373dc794e8: Pulling fs layer\n",
      "9e36cfac5e87: Pulling fs layer\n",
      "15373dc794e8: Waiting\n",
      "9e36cfac5e87: Waiting\n",
      "92c59ec44e08: Verifying Checksum\n",
      "92c59ec44e08: Download complete\n",
      "f7a1c6dad281: Download complete\n",
      "15373dc794e8: Verifying Checksum\n",
      "15373dc794e8: Download complete\n",
      "20ca33a0aa64: Verifying Checksum\n",
      "20ca33a0aa64: Download complete\n",
      "9e36cfac5e87: Verifying Checksum\n",
      "9e36cfac5e87: Download complete\n",
      "f7a1c6dad281: Pull complete\n",
      "92c59ec44e08: Pull complete\n",
      "20ca33a0aa64: Pull complete\n",
      "15373dc794e8: Pull complete\n",
      "9e36cfac5e87: Pull complete\n",
      "Digest: sha256:aeeccd46a37f57b9f28aa033982a9c51f448da3ad720f9d7c63c17bb3e95b18a\n",
      "Status: Downloaded newer image for public.ecr.aws/docker/library/python:3.7-slim\n",
      " ---> 67290a4b6a03\n",
      "Step 2/12 : RUN apt-get -y update && apt-get install -y --no-install-recommends wget git\n",
      " ---> Running in 247550cf5e84\n",
      "Get:1 http://security.debian.org/debian-security bullseye-security InRelease [44.1 kB]\n",
      "Get:2 http://deb.debian.org/debian bullseye InRelease [116 kB]\n",
      "Get:3 http://deb.debian.org/debian bullseye-updates InRelease [39.4 kB]\n",
      "Get:4 http://security.debian.org/debian-security bullseye-security/main amd64 Packages [120 kB]\n",
      "Get:5 http://deb.debian.org/debian bullseye/main amd64 Packages [8183 kB]\n",
      "Get:6 http://deb.debian.org/debian bullseye-updates/main amd64 Packages [2596 B]\n",
      "Fetched 8505 kB in 1s (7064 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  git-man libbrotli1 libcurl3-gnutls liberror-perl libgdbm-compat4\n",
      "  libldap-2.4-2 libnghttp2-14 libperl5.32 libpsl5 librtmp1 libsasl2-2\n",
      "  libsasl2-modules-db libssh2-1 perl perl-modules-5.32\n",
      "Suggested packages:\n",
      "  gettext-base git-daemon-run | git-daemon-sysvinit git-doc git-el git-email\n",
      "  git-gui gitk gitweb git-cvs git-mediawiki git-svn sensible-utils perl-doc\n",
      "  libterm-readline-gnu-perl | libterm-readline-perl-perl make\n",
      "  libtap-harness-archive-perl\n",
      "Recommended packages:\n",
      "  patch less ssh-client libldap-common publicsuffix libsasl2-modules\n",
      "The following NEW packages will be installed:\n",
      "  git git-man libbrotli1 libcurl3-gnutls liberror-perl libgdbm-compat4\n",
      "  libldap-2.4-2 libnghttp2-14 libperl5.32 libpsl5 librtmp1 libsasl2-2\n",
      "  libsasl2-modules-db libssh2-1 perl perl-modules-5.32 wget\n",
      "0 upgraded, 17 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 17.0 MB of archives.\n",
      "After this operation, 91.8 MB of additional disk space will be used.\n",
      "Get:1 http://security.debian.org/debian-security bullseye-security/main amd64 libsasl2-modules-db amd64 2.1.27+dfsg-2.1+deb11u1 [69.1 kB]\n",
      "Get:2 http://security.debian.org/debian-security bullseye-security/main amd64 libsasl2-2 amd64 2.1.27+dfsg-2.1+deb11u1 [106 kB]\n",
      "Get:3 http://deb.debian.org/debian bullseye/main amd64 perl-modules-5.32 all 5.32.1-4+deb11u2 [2823 kB]\n",
      "Get:4 http://deb.debian.org/debian bullseye/main amd64 libgdbm-compat4 amd64 1.19-2 [44.7 kB]\n",
      "Get:5 http://deb.debian.org/debian bullseye/main amd64 libperl5.32 amd64 5.32.1-4+deb11u2 [4106 kB]\n",
      "Get:6 http://deb.debian.org/debian bullseye/main amd64 perl amd64 5.32.1-4+deb11u2 [293 kB]\n",
      "Get:7 http://deb.debian.org/debian bullseye/main amd64 libpsl5 amd64 0.21.0-1.2 [57.3 kB]\n",
      "Get:8 http://deb.debian.org/debian bullseye/main amd64 wget amd64 1.21-1+deb11u1 [964 kB]\n",
      "Get:9 http://deb.debian.org/debian bullseye/main amd64 libbrotli1 amd64 1.0.9-2+b2 [279 kB]\n",
      "Get:10 http://deb.debian.org/debian bullseye/main amd64 libldap-2.4-2 amd64 2.4.57+dfsg-3 [232 kB]\n",
      "Get:11 http://deb.debian.org/debian bullseye/main amd64 libnghttp2-14 amd64 1.43.0-1 [77.1 kB]\n",
      "Get:12 http://deb.debian.org/debian bullseye/main amd64 librtmp1 amd64 2.4+20151223.gitfa8646d.1-2+b2 [60.8 kB]\n",
      "Get:13 http://deb.debian.org/debian bullseye/main amd64 libssh2-1 amd64 1.9.0-2 [156 kB]\n",
      "Get:14 http://deb.debian.org/debian bullseye/main amd64 libcurl3-gnutls amd64 7.74.0-1.3+deb11u1 [338 kB]\n",
      "Get:15 http://deb.debian.org/debian bullseye/main amd64 liberror-perl all 0.17029-1 [31.0 kB]\n",
      "Get:16 http://deb.debian.org/debian bullseye/main amd64 git-man all 1:2.30.2-1 [1827 kB]\n",
      "Get:17 http://deb.debian.org/debian bullseye/main amd64 git amd64 1:2.30.2-1 [5527 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 17.0 MB in 0s (60.0 MB/s)\n",
      "Selecting previously unselected package perl-modules-5.32.\n",
      "(Reading database ... 7023 files and directories currently installed.)\n",
      "Preparing to unpack .../00-perl-modules-5.32_5.32.1-4+deb11u2_all.deb ...\n",
      "Unpacking perl-modules-5.32 (5.32.1-4+deb11u2) ...\n",
      "Selecting previously unselected package libgdbm-compat4:amd64.\n",
      "Preparing to unpack .../01-libgdbm-compat4_1.19-2_amd64.deb ...\n",
      "Unpacking libgdbm-compat4:amd64 (1.19-2) ...\n",
      "Selecting previously unselected package libperl5.32:amd64.\n",
      "Preparing to unpack .../02-libperl5.32_5.32.1-4+deb11u2_amd64.deb ...\n",
      "Unpacking libperl5.32:amd64 (5.32.1-4+deb11u2) ...\n",
      "Selecting previously unselected package perl.\n",
      "Preparing to unpack .../03-perl_5.32.1-4+deb11u2_amd64.deb ...\n",
      "Unpacking perl (5.32.1-4+deb11u2) ...\n",
      "Selecting previously unselected package libpsl5:amd64.\n",
      "Preparing to unpack .../04-libpsl5_0.21.0-1.2_amd64.deb ...\n",
      "Unpacking libpsl5:amd64 (0.21.0-1.2) ...\n",
      "Selecting previously unselected package wget.\n",
      "Preparing to unpack .../05-wget_1.21-1+deb11u1_amd64.deb ...\n",
      "Unpacking wget (1.21-1+deb11u1) ...\n",
      "Selecting previously unselected package libbrotli1:amd64.\n",
      "Preparing to unpack .../06-libbrotli1_1.0.9-2+b2_amd64.deb ...\n",
      "Unpacking libbrotli1:amd64 (1.0.9-2+b2) ...\n",
      "Selecting previously unselected package libsasl2-modules-db:amd64.\n",
      "Preparing to unpack .../07-libsasl2-modules-db_2.1.27+dfsg-2.1+deb11u1_amd64.deb ...\n",
      "Unpacking libsasl2-modules-db:amd64 (2.1.27+dfsg-2.1+deb11u1) ...\n",
      "Selecting previously unselected package libsasl2-2:amd64.\n",
      "Preparing to unpack .../08-libsasl2-2_2.1.27+dfsg-2.1+deb11u1_amd64.deb ...\n",
      "Unpacking libsasl2-2:amd64 (2.1.27+dfsg-2.1+deb11u1) ...\n",
      "Selecting previously unselected package libldap-2.4-2:amd64.\n",
      "Preparing to unpack .../09-libldap-2.4-2_2.4.57+dfsg-3_amd64.deb ...\n",
      "Unpacking libldap-2.4-2:amd64 (2.4.57+dfsg-3) ...\n",
      "Selecting previously unselected package libnghttp2-14:amd64.\n",
      "Preparing to unpack .../10-libnghttp2-14_1.43.0-1_amd64.deb ...\n",
      "Unpacking libnghttp2-14:amd64 (1.43.0-1) ...\n",
      "Selecting previously unselected package librtmp1:amd64.\n",
      "Preparing to unpack .../11-librtmp1_2.4+20151223.gitfa8646d.1-2+b2_amd64.deb ...\n",
      "Unpacking librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2+b2) ...\n",
      "Selecting previously unselected package libssh2-1:amd64.\n",
      "Preparing to unpack .../12-libssh2-1_1.9.0-2_amd64.deb ...\n",
      "Unpacking libssh2-1:amd64 (1.9.0-2) ...\n",
      "Selecting previously unselected package libcurl3-gnutls:amd64.\n",
      "Preparing to unpack .../13-libcurl3-gnutls_7.74.0-1.3+deb11u1_amd64.deb ...\n",
      "Unpacking libcurl3-gnutls:amd64 (7.74.0-1.3+deb11u1) ...\n",
      "Selecting previously unselected package liberror-perl.\n",
      "Preparing to unpack .../14-liberror-perl_0.17029-1_all.deb ...\n",
      "Unpacking liberror-perl (0.17029-1) ...\n",
      "Selecting previously unselected package git-man.\n",
      "Preparing to unpack .../15-git-man_1%3a2.30.2-1_all.deb ...\n",
      "Unpacking git-man (1:2.30.2-1) ...\n",
      "Selecting previously unselected package git.\n",
      "Preparing to unpack .../16-git_1%3a2.30.2-1_amd64.deb ...\n",
      "Unpacking git (1:2.30.2-1) ...\n",
      "Setting up libpsl5:amd64 (0.21.0-1.2) ...\n",
      "Setting up wget (1.21-1+deb11u1) ...\n",
      "Setting up perl-modules-5.32 (5.32.1-4+deb11u2) ...\n",
      "Setting up libbrotli1:amd64 (1.0.9-2+b2) ...\n",
      "Setting up libnghttp2-14:amd64 (1.43.0-1) ...\n",
      "Setting up libsasl2-modules-db:amd64 (2.1.27+dfsg-2.1+deb11u1) ...\n",
      "Setting up librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2+b2) ...\n",
      "Setting up libgdbm-compat4:amd64 (1.19-2) ...\n",
      "Setting up libperl5.32:amd64 (5.32.1-4+deb11u2) ...\n",
      "Setting up libsasl2-2:amd64 (2.1.27+dfsg-2.1+deb11u1) ...\n",
      "Setting up git-man (1:2.30.2-1) ...\n",
      "Setting up libssh2-1:amd64 (1.9.0-2) ...\n",
      "Setting up libldap-2.4-2:amd64 (2.4.57+dfsg-3) ...\n",
      "Setting up libcurl3-gnutls:amd64 (7.74.0-1.3+deb11u1) ...\n",
      "Setting up perl (5.32.1-4+deb11u2) ...\n",
      "Setting up liberror-perl (0.17029-1) ...\n",
      "Setting up git (1:2.30.2-1) ...\n",
      "Processing triggers for libc-bin (2.31-13+deb11u2) ...\n",
      "Removing intermediate container 247550cf5e84\n",
      " ---> a7c10da1c3a7\n",
      "Step 3/12 : RUN pip3 install numpy pandas scikit-learn==1.0.2\n",
      " ---> Running in ecfa0f95fae9\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "Collecting scikit-learn==1.0.2\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "Collecting scipy>=1.1.0\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting six>=1.5\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: six, numpy, threadpoolctl, scipy, pytz, python-dateutil, joblib, scikit-learn, pandas\n",
      "Successfully installed joblib-1.1.0 numpy-1.21.5 pandas-1.3.5 python-dateutil-2.8.2 pytz-2021.3 scikit-learn-1.0.2 scipy-1.7.3 six-1.16.0 threadpoolctl-3.1.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container ecfa0f95fae9\n",
      " ---> 29a69d158666\n",
      "Step 4/12 : RUN pip install awscli==1.22.67 boto3==1.21.12\n",
      " ---> Running in 9db75a41841a\n",
      "Collecting awscli==1.22.67\n",
      "  Downloading awscli-1.22.67-py3-none-any.whl (3.8 MB)\n",
      "Collecting boto3==1.21.12\n",
      "  Downloading boto3-1.21.12-py3-none-any.whl (132 kB)\n",
      "Collecting rsa<4.8,>=3.1.2\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting colorama<0.4.4,>=0.2.5\n",
      "  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
      "Collecting PyYAML<5.5,>=3.10\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
      "Collecting botocore==1.24.12\n",
      "  Downloading botocore-1.24.12-py3-none-any.whl (8.6 MB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/site-packages (from botocore==1.24.12->awscli==1.22.67) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.24.12->awscli==1.22.67) (1.16.0)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Installing collected packages: urllib3, jmespath, pyasn1, botocore, s3transfer, rsa, PyYAML, docutils, colorama, boto3, awscli\n",
      "Successfully installed PyYAML-5.4.1 awscli-1.22.67 boto3-1.21.12 botocore-1.24.12 colorama-0.4.3 docutils-0.15.2 jmespath-0.10.0 pyasn1-0.4.8 rsa-4.7.2 s3transfer-0.5.2 urllib3-1.26.8\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 9db75a41841a\n",
      " ---> 171b8dfe751a\n",
      "Step 5/12 : RUN pip3 install sagemaker==2.77.1 sagemaker-experiments==0.1.35\n",
      " ---> Running in 39fd5df09593\n",
      "Collecting sagemaker==2.77.1\n",
      "  Downloading sagemaker-2.77.1.tar.gz (513 kB)\n",
      "Collecting sagemaker-experiments==0.1.35\n",
      "  Downloading sagemaker_experiments-0.1.35-py3-none-any.whl (42 kB)\n",
      "Collecting attrs==20.3.0\n",
      "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: boto3>=1.20.21 in /usr/local/lib/python3.7/site-packages (from sagemaker==2.77.1) (1.21.12)\n",
      "Collecting google-pasta\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/site-packages (from sagemaker==2.77.1) (1.21.5)\n",
      "Collecting protobuf>=3.1\n",
      "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Collecting protobuf3-to-dict>=0.1.5\n",
      "  Downloading protobuf3-to-dict-0.1.5.tar.gz (3.5 kB)\n",
      "Collecting smdebug_rulesconfig==1.0.1\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Collecting importlib-metadata>=1.4.0\n",
      "  Downloading importlib_metadata-4.11.2-py3-none-any.whl (17 kB)\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (from sagemaker==2.77.1) (1.3.5)\n",
      "Collecting pathos\n",
      "  Downloading pathos-0.2.8-py2.py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.12 in /usr/local/lib/python3.7/site-packages (from boto3>=1.20.21->sagemaker==2.77.1) (1.24.12)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/site-packages (from boto3>=1.20.21->sagemaker==2.77.1) (0.5.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3>=1.20.21->sagemaker==2.77.1) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.12->boto3>=1.20.21->sagemaker==2.77.1) (1.26.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.12->boto3>=1.20.21->sagemaker==2.77.1) (2.8.2)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.7.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker==2.77.1) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas->sagemaker==2.77.1) (2021.3)\n",
      "Collecting ppft>=1.6.6.4\n",
      "  Downloading ppft-1.6.6.4-py3-none-any.whl (65 kB)\n",
      "Collecting dill>=0.3.4\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting multiprocess>=0.70.12\n",
      "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
      "Collecting pox>=0.3.0\n",
      "  Downloading pox-0.3.0-py2.py3-none-any.whl (30 kB)\n",
      "Building wheels for collected packages: sagemaker, protobuf3-to-dict\n",
      "  Building wheel for sagemaker (setup.py): started\n",
      "  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.77.1-py2.py3-none-any.whl size=711682 sha256=9aa6b94f9701291bde187e3ea36862f142eec45366b55dbdcc1c426769440331\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/f0/3e/fb77306bcb1e3cfb95c52e21a23184e9dcb77a2a3a7922e578\n",
      "  Building wheel for protobuf3-to-dict (setup.py): started\n",
      "  Building wheel for protobuf3-to-dict (setup.py): finished with status 'done'\n",
      "  Created wheel for protobuf3-to-dict: filename=protobuf3_to_dict-0.1.5-py3-none-any.whl size=4030 sha256=ac1f4f33d01a5dc993e04bb7170bdd09631edd6434dd0071b45d5979a992f619\n",
      "  Stored in directory: /root/.cache/pip/wheels/ce/a0/8b/995ce2fbaf0e9fe7eb91da84e99e84d1b35cfaa555f2b8f1c7\n",
      "Successfully built sagemaker protobuf3-to-dict\n",
      "Installing collected packages: dill, zipp, typing-extensions, pyparsing, protobuf, ppft, pox, multiprocess, smdebug-rulesconfig, protobuf3-to-dict, pathos, packaging, importlib-metadata, google-pasta, attrs, sagemaker-experiments, sagemaker\n",
      "Successfully installed attrs-20.3.0 dill-0.3.4 google-pasta-0.2.0 importlib-metadata-4.11.2 multiprocess-0.70.12.2 packaging-21.3 pathos-0.2.8 pox-0.3.0 ppft-1.6.6.4 protobuf-3.19.4 protobuf3-to-dict-0.1.5 pyparsing-3.0.7 sagemaker-2.77.1 sagemaker-experiments-0.1.35 smdebug-rulesconfig-1.0.1 typing-extensions-4.1.1 zipp-3.7.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 39fd5df09593\n",
      " ---> bfe423e2fdf5\n",
      "Step 6/12 : RUN pip3 install git-remote-codecommit\n",
      " ---> Running in e74ddea7762b\n",
      "Collecting git-remote-codecommit\n",
      "  Downloading git-remote-codecommit-1.16.tar.gz (7.0 kB)\n",
      "Requirement already satisfied: botocore>=1.17.0 in /usr/local/lib/python3.7/site-packages (from git-remote-codecommit) (1.24.12)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/site-packages (from botocore>=1.17.0->git-remote-codecommit) (2.8.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from botocore>=1.17.0->git-remote-codecommit) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/site-packages (from botocore>=1.17.0->git-remote-codecommit) (1.26.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.17.0->git-remote-codecommit) (1.16.0)\n",
      "Building wheels for collected packages: git-remote-codecommit\n",
      "  Building wheel for git-remote-codecommit (setup.py): started\n",
      "  Building wheel for git-remote-codecommit (setup.py): finished with status 'done'\n",
      "  Created wheel for git-remote-codecommit: filename=git_remote_codecommit-1.16-py3-none-any.whl size=7131 sha256=cb202636b91014755dcdc29046624679549cf4814cfd48c2583e2bc1e99b04b9\n",
      "  Stored in directory: /root/.cache/pip/wheels/84/90/b1/a550d585720960a2a46103d42176c8870b6446246bb67ff7b3\n",
      "Successfully built git-remote-codecommit\n",
      "Installing collected packages: git-remote-codecommit\n",
      "Successfully installed git-remote-codecommit-1.16\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container e74ddea7762b\n",
      " ---> 0df6f839e91c\n",
      "Step 7/12 : RUN pip3 install dvc==2.8.3 s3fs==2021.10.1\n",
      " ---> Running in f28203ebd963\n",
      "Collecting dvc==2.8.3\n",
      "  Downloading dvc-2.8.3-py3-none-any.whl (399 kB)\n",
      "Collecting s3fs==2021.10.1\n",
      "  Downloading s3fs-2021.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting dulwich>=0.20.23\n",
      "  Downloading dulwich-0.20.33-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (550 kB)\n",
      "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.7/site-packages (from dvc==2.8.3) (21.3)\n",
      "Collecting networkx>=2.5\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "Collecting nanotime>=0.5.2\n",
      "  Downloading nanotime-0.5.2.tar.gz (3.2 kB)\n",
      "Collecting importlib-resources>=5.2.2\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.7/site-packages (from dvc==2.8.3) (0.4.3)\n",
      "Collecting toml>=0.10.1\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/site-packages (from dvc==2.8.3) (4.11.2)\n",
      "Collecting tabulate>=0.8.7\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting flatten-dict<1,>=0.4.1\n",
      "  Downloading flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting dpath<3,>=2.0.2\n",
      "  Downloading dpath-2.0.6-py3-none-any.whl (15 kB)\n",
      "Collecting fsspec[http]>=2021.10.1\n",
      "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
      "Collecting pygtrie>=2.3.2\n",
      "  Downloading pygtrie-2.4.2.tar.gz (35 kB)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting rich>=10.13.0\n",
      "  Downloading rich-11.2.0-py3-none-any.whl (217 kB)\n",
      "Collecting zc.lockfile>=1.2.1\n",
      "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting dictdiffer>=0.8.1\n",
      "  Downloading dictdiffer-0.9.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting pydot>=1.2.4\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/site-packages (from dvc==2.8.3) (4.1.1)\n",
      "Collecting python-benedict>=0.24.2\n",
      "  Downloading python_benedict-0.25.0-py3-none-any.whl (40 kB)\n",
      "Collecting flufl.lock>=5\n",
      "  Downloading flufl.lock-7.0-py3-none-any.whl (11 kB)\n",
      "Collecting diskcache>=5.2.1\n",
      "  Downloading diskcache-5.4.0-py3-none-any.whl (44 kB)\n",
      "Collecting ply>=3.9\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
      "Collecting grandalf==0.6\n",
      "  Downloading grandalf-0.6-py3-none-any.whl (31 kB)\n",
      "Collecting ruamel.yaml>=0.17.11\n",
      "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
      "Requirement already satisfied: pyasn1>=0.4.1 in /usr/local/lib/python3.7/site-packages (from dvc==2.8.3) (0.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.4.7 in /usr/local/lib/python3.7/site-packages (from dvc==2.8.3) (3.0.7)\n",
      "Collecting shtab<2,>=1.3.4\n",
      "  Downloading shtab-1.5.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting configobj>=5.0.6\n",
      "  Downloading configobj-5.0.6.tar.gz (33 kB)\n",
      "Collecting gitpython>3\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "Collecting pathspec<0.10.0,>=0.9.0\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting aiohttp-retry>=2.4.5\n",
      "  Downloading aiohttp_retry-2.4.6-py3-none-any.whl (7.7 kB)\n",
      "Collecting funcy>=1.14\n",
      "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
      "Collecting requests>=2.22.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting tqdm<5,>=4.45.0\n",
      "  Downloading tqdm-4.63.0-py2.py3-none-any.whl (76 kB)\n",
      "Collecting pygit2>=1.5.0\n",
      "  Downloading pygit2-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "Collecting psutil>=5.8.0\n",
      "  Downloading psutil-5.9.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "Collecting voluptuous>=0.11.7\n",
      "  Downloading voluptuous-0.12.2.tar.gz (48 kB)\n",
      "Collecting distro>=1.3.0\n",
      "  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\n",
      "Collecting fsspec==2021.10.1\n",
      "  Downloading fsspec-2021.10.1-py3-none-any.whl (125 kB)\n",
      "Collecting aiobotocore~=1.4.1\n",
      "  Downloading aiobotocore-1.4.2.tar.gz (52 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Collecting botocore<1.20.107,>=1.20.106\n",
      "  Downloading botocore-1.20.106-py2.py3-none-any.whl (7.7 MB)\n",
      "Collecting aiohttp>=3.3.1\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "Collecting wrapt>=1.10.10\n",
      "  Downloading wrapt-1.13.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (79 kB)\n",
      "Collecting aioitertools>=0.5.1\n",
      "  Downloading aioitertools-0.10.0-py3-none-any.whl (23 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/site-packages (from aiohttp>=3.3.1->aiobotocore~=1.4.1->s3fs==2021.10.1) (20.3.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/site-packages (from botocore<1.20.107,>=1.20.106->aiobotocore~=1.4.1->s3fs==2021.10.1) (1.26.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/site-packages (from botocore<1.20.107,>=1.20.106->aiobotocore~=1.4.1->s3fs==2021.10.1) (2.8.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from botocore<1.20.107,>=1.20.106->aiobotocore~=1.4.1->s3fs==2021.10.1) (0.10.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from configobj>=5.0.6->dvc==2.8.3) (1.16.0)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Collecting atpublic>=2.3\n",
      "  Downloading atpublic-3.0.1-py3-none-any.whl (4.8 kB)\n",
      "Collecting fsspec[http]>=2021.10.1\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
      "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata>=1.4->dvc==2.8.3) (3.7.0)\n",
      "Collecting cffi>=1.9.1\n",
      "  Downloading cffi-1.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (427 kB)\n",
      "Collecting cached-property\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting python-slugify<7.0.0,>=6.0.1\n",
      "  Downloading python_slugify-6.1.1-py2.py3-none-any.whl (9.1 kB)\n",
      "Collecting xmltodict<1.0.0,>=0.12.0\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting ftfy<7.0.0,>=6.0.0\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Collecting mailchecker<5.0.0,>=4.1.0\n",
      "  Downloading mailchecker-4.1.13.tar.gz (230 kB)\n",
      "Collecting phonenumbers<9.0.0,>=8.12.0\n",
      "  Downloading phonenumbers-8.12.44-py2.py3-none-any.whl (2.6 MB)\n",
      "Collecting python-fsutil<1.0.0,>=0.6.0\n",
      "  Downloading python_fsutil-0.6.0-py3-none-any.whl (11 kB)\n",
      "Collecting pyyaml<7.0,>=6.0\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "Collecting wcwidth>=0.2.5\n",
      "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "Collecting pygments<3.0.0,>=2.6.0\n",
      "  Downloading Pygments-2.11.2-py3-none-any.whl (1.1 MB)\n",
      "Collecting ruamel.yaml.clib>=0.2.6\n",
      "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from zc.lockfile>=1.2.1->dvc==2.8.3) (57.5.0)\n",
      "Building wheels for collected packages: aiobotocore, configobj, nanotime, pygtrie, mailchecker, voluptuous, future\n",
      "  Building wheel for aiobotocore (setup.py): started\n",
      "  Building wheel for aiobotocore (setup.py): finished with status 'done'\n",
      "  Created wheel for aiobotocore: filename=aiobotocore-1.4.2-py3-none-any.whl size=49926 sha256=9660ca04b793951b271136c6390148b38b51ec4a39f287db30c8a0a611f4c06a\n",
      "  Stored in directory: /root/.cache/pip/wheels/33/e7/d9/b297a9aa9c43d56bc2463e6e2771655ff638f30b30f0b61fcb\n",
      "  Building wheel for configobj (setup.py): started\n",
      "  Building wheel for configobj (setup.py): finished with status 'done'\n",
      "  Created wheel for configobj: filename=configobj-5.0.6-py3-none-any.whl size=34547 sha256=178470895f0860cf59b960ac6f1cfa281dc7cc3bfb1dda50122b72a36019e30a\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/c4/19/13d74440f2a571841db6b6e0a273694327498884dafb9cf978\n",
      "  Building wheel for nanotime (setup.py): started\n",
      "  Building wheel for nanotime (setup.py): finished with status 'done'\n",
      "  Created wheel for nanotime: filename=nanotime-0.5.2-py3-none-any.whl size=2441 sha256=58fe899cfedf08ccad94a6cae182edf50e3dbd6a15de22c841d1365182644879\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/92/aa/456d462c908b4e210c3928f778d28f94049fc9e47af8b191c9\n",
      "  Building wheel for pygtrie (setup.py): started\n",
      "  Building wheel for pygtrie (setup.py): finished with status 'done'\n",
      "  Created wheel for pygtrie: filename=pygtrie-2.4.2-py3-none-any.whl size=19063 sha256=f5c4a44e3eb96a2e01f185ed758b52d96425f9cd2a8375bbbaff021fe36e9337\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/f8/ba/1d828b1603ea422686eb694253a43cb3a5901ea4696c1e0603\n",
      "  Building wheel for mailchecker (setup.py): started\n",
      "  Building wheel for mailchecker (setup.py): finished with status 'done'\n",
      "  Created wheel for mailchecker: filename=mailchecker-4.1.13-py3-none-any.whl size=230464 sha256=86f2dc7a4f2b59d38972b17218d36afa3ec4fcb5473d11da236fe3984cbc865e\n",
      "  Stored in directory: /root/.cache/pip/wheels/4f/94/bc/30ecf5d89887023ffbda109cc28f38d5f6b4b27b8dfe682d51\n",
      "  Building wheel for voluptuous (setup.py): started\n",
      "  Building wheel for voluptuous (setup.py): finished with status 'done'\n",
      "  Created wheel for voluptuous: filename=voluptuous-0.12.2-py3-none-any.whl size=29563 sha256=ae59b48a9f09782c927714b4ac1f0bd31fa59ec393f9c064887aeff4aca27b11\n",
      "  Stored in directory: /root/.cache/pip/wheels/ce/40/e9/5aba7699054584e118b04cc18d4d8f1f15f27af4a0d65ef4b4\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=f0f58066b4e60c5b0d0a7b08449758dea1ab17b9a5d086ee94911fe6ebe88f1b\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "Successfully built aiobotocore configobj nanotime pygtrie mailchecker voluptuous future\n",
      "Installing collected packages: multidict, idna, frozenlist, yarl, wcwidth, text-unidecode, smmap, pycparser, charset-normalizer, certifi, asynctest, async-timeout, aiosignal, xmltodict, wrapt, toml, ruamel.yaml.clib, requests, pyyaml, python-slugify, python-fsutil, pygments, psutil, phonenumbers, mailchecker, gitdb, future, ftfy, fsspec, commonmark, cffi, cached-property, botocore, atpublic, aioitertools, aiohttp, zc.lockfile, voluptuous, tqdm, tabulate, shtab, shortuuid, ruamel.yaml, rich, python-benedict, pygtrie, pygit2, pydot, ply, pathspec, networkx, nanotime, importlib-resources, grandalf, gitpython, funcy, flufl.lock, flatten-dict, dulwich, dpath, distro, diskcache, dictdiffer, configobj, appdirs, aiohttp-retry, aiobotocore, s3fs, dvc\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.24.12\n",
      "    Uninstalling botocore-1.24.12:\n",
      "      Successfully uninstalled botocore-1.24.12\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "boto3 1.21.12 requires botocore<1.25.0,>=1.24.12, but you have botocore 1.20.106 which is incompatible.\n",
      "awscli 1.22.67 requires botocore==1.24.12, but you have botocore 1.20.106 which is incompatible.\n",
      "awscli 1.22.67 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "\u001b[0mSuccessfully installed aiobotocore-1.4.2 aiohttp-3.8.1 aiohttp-retry-2.4.6 aioitertools-0.10.0 aiosignal-1.2.0 appdirs-1.4.4 async-timeout-4.0.2 asynctest-0.13.0 atpublic-3.0.1 botocore-1.20.106 cached-property-1.5.2 certifi-2021.10.8 cffi-1.15.0 charset-normalizer-2.0.12 commonmark-0.9.1 configobj-5.0.6 dictdiffer-0.9.0 diskcache-5.4.0 distro-1.7.0 dpath-2.0.6 dulwich-0.20.33 dvc-2.8.3 flatten-dict-0.4.2 flufl.lock-7.0 frozenlist-1.3.0 fsspec-2021.10.1 ftfy-6.1.1 funcy-1.17 future-0.18.2 gitdb-4.0.9 gitpython-3.1.27 grandalf-0.6 idna-3.3 importlib-resources-5.4.0 mailchecker-4.1.13 multidict-6.0.2 nanotime-0.5.2 networkx-2.6.3 pathspec-0.9.0 phonenumbers-8.12.44 ply-3.11 psutil-5.9.0 pycparser-2.21 pydot-1.4.2 pygit2-1.9.0 pygments-2.11.2 pygtrie-2.4.2 python-benedict-0.25.0 python-fsutil-0.6.0 python-slugify-6.1.1 pyyaml-6.0 requests-2.27.1 rich-11.2.0 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 s3fs-2021.10.1 shortuuid-1.0.8 shtab-1.5.3 smmap-5.0.0 tabulate-0.8.9 text-unidecode-1.3 toml-0.10.2 tqdm-4.63.0 voluptuous-0.12.2 wcwidth-0.2.5 wrapt-1.13.3 xmltodict-0.12.0 yarl-1.7.2 zc.lockfile-2.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container f28203ebd963\n",
      " ---> 6f055718bf97\n",
      "Step 8/12 : RUN pip3 install git-remote-codecommit sagemaker-experiments\n",
      " ---> Running in cb0678830292\n",
      "Requirement already satisfied: git-remote-codecommit in /usr/local/lib/python3.7/site-packages (1.16)\n",
      "Requirement already satisfied: sagemaker-experiments in /usr/local/lib/python3.7/site-packages (0.1.35)\n",
      "Requirement already satisfied: botocore>=1.17.0 in /usr/local/lib/python3.7/site-packages (from git-remote-codecommit) (1.20.106)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /usr/local/lib/python3.7/site-packages (from sagemaker-experiments) (1.21.12)\n",
      "Collecting botocore>=1.17.0\n",
      "  Downloading botocore-1.24.15-py3-none-any.whl (8.6 MB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.5.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/site-packages (from botocore>=1.17.0->git-remote-codecommit) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/site-packages (from botocore>=1.17.0->git-remote-codecommit) (1.26.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.17.0->git-remote-codecommit) (1.16.0)\n",
      "Installing collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.106\n",
      "    Uninstalling botocore-1.20.106:\n",
      "      Successfully uninstalled botocore-1.20.106\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.22.67 requires botocore==1.24.12, but you have botocore 1.24.15 which is incompatible.\n",
      "awscli 1.22.67 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "aiobotocore 1.4.2 requires botocore<1.20.107,>=1.20.106, but you have botocore 1.24.15 which is incompatible.\n",
      "\u001b[0mSuccessfully installed botocore-1.24.15\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container cb0678830292\n",
      " ---> c38e592a203b\n",
      "Step 9/12 : RUN git config --global user.email \"sagemaker-processing@example.com\"\n",
      " ---> Running in 37805aa0554d\n",
      "Removing intermediate container 37805aa0554d\n",
      " ---> 197f657a78b7\n",
      "Step 10/12 : RUN git config --global user.name \"SageMaker ProcessingJob User\"\n",
      " ---> Running in 3f5a3a3cd5bd\n",
      "Removing intermediate container 3f5a3a3cd5bd\n",
      " ---> 1012409c353f\n",
      "Step 11/12 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in 60f17d87939e\n",
      "Removing intermediate container 60f17d87939e\n",
      " ---> c73a61aef921\n",
      "Step 12/12 : ENTRYPOINT [\"python3\"]\n",
      " ---> Running in 19a42e387a8f\n",
      "Removing intermediate container 19a42e387a8f\n",
      " ---> 0cced5ae072e\n",
      "Successfully built 0cced5ae072e\n",
      "Successfully tagged sagemaker-processing-dvc:latest\n",
      "\n",
      "[Container] 2022/03/08 21:46:27 Running command docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "\n",
      "[Container] 2022/03/08 21:46:27 Phase complete: BUILD State: SUCCEEDED\n",
      "[Container] 2022/03/08 21:46:27 Phase context status code:  Message:\n",
      "[Container] 2022/03/08 21:46:27 Entering phase POST_BUILD\n",
      "[Container] 2022/03/08 21:46:27 Running command echo Build completed on `date`\n",
      "Build completed on Tue Mar 8 21:46:27 UTC 2022\n",
      "\n",
      "[Container] 2022/03/08 21:46:27 Running command echo Pushing the Docker image...\n",
      "Pushing the Docker image...\n",
      "\n",
      "[Container] 2022/03/08 21:46:27 Running command docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "The push refers to repository [583558296381.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-processing-dvc]\n",
      "afaea0d6e495: Preparing\n",
      "0194fc1465d9: Preparing\n",
      "5d64180f6079: Preparing\n",
      "05b9f2535e7f: Preparing\n",
      "a4347751677f: Preparing\n",
      "509403603605: Preparing\n",
      "239ef72fe1ef: Preparing\n",
      "81759c54d075: Preparing\n",
      "0a4249f66b20: Preparing\n",
      "5346dd72bba4: Preparing\n",
      "9e7155bb7167: Preparing\n",
      "1daec571e2cb: Preparing\n",
      "7fce09c1d950: Preparing\n",
      "1401df2b50d5: Preparing\n",
      "509403603605: Waiting\n",
      "239ef72fe1ef: Waiting\n",
      "81759c54d075: Waiting\n",
      "0a4249f66b20: Waiting\n",
      "5346dd72bba4: Waiting\n",
      "9e7155bb7167: Waiting\n",
      "1daec571e2cb: Waiting\n",
      "1401df2b50d5: Waiting\n",
      "7fce09c1d950: Waiting\n",
      "0194fc1465d9: Pushed\n",
      "afaea0d6e495: Pushed\n",
      "a4347751677f: Pushed\n",
      "5d64180f6079: Pushed\n",
      "509403603605: Pushed\n",
      "5346dd72bba4: Layer already exists\n",
      "9e7155bb7167: Layer already exists\n",
      "1daec571e2cb: Layer already exists\n",
      "7fce09c1d950: Layer already exists\n",
      "1401df2b50d5: Layer already exists\n",
      "05b9f2535e7f: Pushed\n",
      "239ef72fe1ef: Pushed\n",
      "0a4249f66b20: Pushed\n",
      "81759c54d075: Pushed\n",
      "latest: digest: sha256:cf87f05b5fcf287aa0f379e0aee9d979044b995c5987dc044c1420a0e27b3147 size: 3266\n",
      "\n",
      "[Container] 2022/03/08 21:46:56 Phase complete: POST_BUILD State: SUCCEEDED\n",
      "[Container] 2022/03/08 21:46:56 Phase context status code:  Message:\n",
      "\n",
      "Image URI: 583558296381.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-processing-dvc:latest\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of the image\n",
    "image_name=sagemaker-processing-dvc\n",
    "\n",
    "cd processor-container\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-1 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-eu-west-1}\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${image_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${image_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "sm-docker build . --repository \"${image_name}:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker:Creating processing-job with name sagemaker-scikit-learn-2022-03-08-21-47-34-529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2022-03-08-21-47-34-529\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-eu-west-1-583558296381/DEMO-sagemaker-experiments-dvc/input/dataset.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-eu-west-1-583558296381/sagemaker-scikit-learn-2022-03-08-21-47-34-529/input/code/preprocessing-experiment-1.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  []\n",
      "...........................\u001b[34mArgumentParser(prog='preprocessing-experiment-1.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)\u001b[0m\n",
      "\u001b[34mInstall git-remote-codecommit and sagemaker-experiments\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 22.0.2; however, version 22.0.4 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34mInstall DVC and drivers for S3\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires botocore==1.19.4, but you have botocore 1.20.106 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires psutil==5.7.2, but you have psutil 5.9.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mboto3 1.16.4 requires botocore<1.20.0,>=1.19.4, but you have botocore 1.20.106 which is incompatible.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 22.0.2; however, version 22.0.4 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34mdependencies installed successfully\u001b[0m\n",
      "\u001b[34mConfigure git\u001b[0m\n",
      "\u001b[34mConfigure git to pull authenticated from CodeCommit\u001b[0m\n",
      "\u001b[34mCloning repo: codecommit::eu-west-1://sagemaker-dvc-sample\u001b[0m\n",
      "\u001b[34mCloning into 'sagemaker-dvc-sample'...\u001b[0m\n",
      "\u001b[34mremote: #015remote: Counting objects: 0#015remote: Counting objects: 58#015remote: Counting objects: 58#015remote: Counting objects: 58, done.        \u001b[0m\n",
      "\u001b[34mRead dataset\u001b[0m\n",
      "\u001b[34mcreate train, validation, test\u001b[0m\n",
      "\u001b[34mdata created\u001b[0m\n",
      "\u001b[34mCreate branch experiment-1\u001b[0m\n",
      "\u001b[34mSwitched to a new branch 'experiment-1'\u001b[0m\n",
      "\u001b[34mCreate a new branch: experiment-1\u001b[0m\n",
      "\u001b[34mAdd files to DVC\u001b[0m\n",
      "\u001b[34mTo track the changes with git, run:\u001b[0m\n",
      "\u001b[34m#011git add train/.gitignore train/california_train.csv.dvc\u001b[0m\n",
      "\u001b[34mTo track the changes with git, run:\u001b[0m\n",
      "\u001b[34m#011git add validation/california_validation.csv.dvc validation/.gitignore\u001b[0m\n",
      "\u001b[34mTo track the changes with git, run:\u001b[0m\n",
      "\u001b[34m#011git add test/california_test.csv.dvc test/.gitignore\u001b[0m\n",
      "\u001b[34m[experiment-1 3fc3232] 'add data for experiment-1'\n",
      " 6 files changed, 15 insertions(+)\n",
      " create mode 100644 dataset/test/.gitignore\n",
      " create mode 100644 dataset/test/california_test.csv.dvc\n",
      " create mode 100644 dataset/train/.gitignore\n",
      " create mode 100644 dataset/train/california_train.csv.dvc\n",
      " create mode 100644 dataset/validation/.gitignore\n",
      " create mode 100644 dataset/validation/california_validation.csv.dvc\u001b[0m\n",
      "\u001b[34mPush data to DVC\u001b[0m\n",
      "\u001b[34m3 files pushed\u001b[0m\n",
      "\u001b[34mPush dvc metadata to git\u001b[0m\n",
      "\u001b[34mTo codecommit::eu-west-1://sagemaker-dvc-sample\n",
      " ! [rejected]        experiment-1 -> experiment-1 (non-fast-forward)\u001b[0m\n",
      "\u001b[34merror: failed to push some refs to 'codecommit::eu-west-1://sagemaker-dvc-sample'\u001b[0m\n",
      "\u001b[34mhint: Updates were rejected because the tip of your current branch is behind\u001b[0m\n",
      "\u001b[34mhint: its remote counterpart. Integrate the remote changes (e.g.\u001b[0m\n",
      "\u001b[34mhint: 'git pull ...') before pushing again.\u001b[0m\n",
      "\u001b[34mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/preprocessing-experiment-1.py\", line 98, in <module>\n",
      "    sync_data_with_dvc(args.dvc_branch)\n",
      "  File \"/opt/ml/processing/input/code/preprocessing-experiment-1.py\", line 81, in sync_data_with_dvc\n",
      "    subprocess.check_call(['git', 'push', '--set-upstream', 'origin', branch])\n",
      "  File \"/miniconda3/lib/python3.7/subprocess.py\", line 363, in check_call\n",
      "    raise CalledProcessError(retcode, cmd)\u001b[0m\n",
      "\u001b[34msubprocess.CalledProcessError: Command '['git', 'push', '--set-upstream', 'origin', 'experiment-1']' returned non-zero exit status 1.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Processing job sagemaker-scikit-learn-2022-03-08-21-47-34-529: Failed. Reason: AlgorithmError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#ScriptProcessor to use a custom made image\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#https://docs.aws.amazon.com/sagemaker/latest/dg/processing-container-run-scripts.html\u001b[39;00m\n\u001b[1;32m     14\u001b[0m experiment_config\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperimentName\u001b[39m\u001b[38;5;124m\"\u001b[39m: my_experiment\u001b[38;5;241m.\u001b[39mexperiment_name,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrialName\u001b[39m\u001b[38;5;124m\"\u001b[39m: my_first_trial\u001b[38;5;241m.\u001b[39mtrial_name,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrialComponentDisplayName\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m }\n\u001b[0;32m---> 20\u001b[0m \u001b[43msklearn_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocessing-experiment-1.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mProcessingInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms3_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/opt/ml/processing/input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_config\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/dvc/lib/python3.8/site-packages/sagemaker/processing.py:553\u001b[0m, in \u001b[0;36mScriptProcessor.run\u001b[0;34m(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_job)\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/dvc/lib/python3.8/site-packages/sagemaker/processing.py:962\u001b[0m, in \u001b[0;36mProcessingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;124;03m\"\"\"Waits for the processing job to complete.\u001b[39;00m\n\u001b[1;32m    956\u001b[0m \n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m    logs (bool): Whether to show the logs produced by the job (default: True).\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \n\u001b[1;32m    960\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs:\n\u001b[0;32m--> 962\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_processing_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_processing_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m/opt/conda/envs/dvc/lib/python3.8/site-packages/sagemaker/session.py:3842\u001b[0m, in \u001b[0;36mSession.logs_for_processing_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   3839\u001b[0m             state \u001b[38;5;241m=\u001b[39m LogState\u001b[38;5;241m.\u001b[39mJOB_COMPLETE\n\u001b[1;32m   3841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 3842\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3843\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   3844\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/dvc/lib/python3.8/site-packages/sagemaker/session.py:3301\u001b[0m, in \u001b[0;36mSession._check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3299\u001b[0m reason \u001b[38;5;241m=\u001b[39m desc\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailureReason\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(No reason provided)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3300\u001b[0m job_type \u001b[38;5;241m=\u001b[39m status_key_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJobStatus\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m job\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3301\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   3302\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError for \u001b[39m\u001b[38;5;132;01m{job_type}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{job_name}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{status}\u001b[39;00m\u001b[38;5;124m. Reason: \u001b[39m\u001b[38;5;132;01m{reason}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   3303\u001b[0m         job_type\u001b[38;5;241m=\u001b[39mjob_type, job_name\u001b[38;5;241m=\u001b[39mjob, status\u001b[38;5;241m=\u001b[39mstatus, reason\u001b[38;5;241m=\u001b[39mreason\n\u001b[1;32m   3304\u001b[0m     ),\n\u001b[1;32m   3305\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3306\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   3307\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Processing job sagemaker-scikit-learn-2022-03-08-21-47-34-529: Failed. Reason: AlgorithmError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1\n",
    ")\n",
    "\n",
    "#ScriptProcessor to use a custom made image\n",
    "#https://docs.aws.amazon.com/sagemaker/latest/dg/processing-container-run-scripts.html\n",
    "\n",
    "experiment_config={\n",
    "    \"ExperimentName\": my_experiment.experiment_name,\n",
    "    \"TrialName\": my_first_trial.trial_name,\n",
    "    \"TrialComponentDisplayName\": \"Training\"\n",
    "}\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code='preprocessing-experiment-1.py',\n",
    "    inputs=[ProcessingInput(source=s3_data_path, destination=\"/opt/ml/processing/input\")],\n",
    "    experiment_config=experiment_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocessing-experiment-2.py\n",
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: MIT-0\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read data locally\n",
    "input_data_path = os.path.join(\"/opt/ml/processing/input\", \"dataset.csv\")\n",
    "\n",
    "prefix = '/opt/ml/'\n",
    "input_path = prefix + 'processing/input'\n",
    "dataset_path = prefix + input_path\n",
    "train_channel_name = 'train'\n",
    "validation_channel_name = 'validation'\n",
    "base_dir = './sagemaker-dvc-sample/dataset'\n",
    "\n",
    "train_path = os.path.join(dataset_path, train_channel_name)\n",
    "validation_path = os.path.join(dataset_path, validation_channel_name)\n",
    "\n",
    "#my_tracker = tracker.Tracker.load()\n",
    "\n",
    "def clone_dvc_git_repo(dvc_repo_url):\n",
    "    print(f\"Cloning repo: {dvc_repo_url}\")\n",
    "    subprocess.check_call([\"git\", \"clone\", dvc_repo_url])\n",
    "\n",
    "def generate_train_validation_files(ratio):\n",
    "    for path in ['train', 'validation', 'test']:\n",
    "        output_dir = Path(f\"{base_dir}/{path}/\")\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"Read dataset\")\n",
    "    dataset = pd.read_csv(input_data_path)\n",
    "    train, other = train_test_split(dataset, test_size=ratio)\n",
    "    validation, test = train_test_split(other, test_size=ratio)\n",
    "    \n",
    "    print(\"create train, validation, test\")\n",
    "    pd.DataFrame(train).to_csv(f\"{base_dir}/train/california_train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(f\"{base_dir}/validation/california_validation.csv\", header=False, index=False)\n",
    "    pd.DataFrame(test).to_csv(f\"{base_dir}/test/california_test.csv\", header=False, index=False)\n",
    "    print(\"data created\")\n",
    "\n",
    "def sync_data_with_dvc(branch):\n",
    "    os.chdir(base_dir)\n",
    "    print(f\"Create branch {branch}\")\n",
    "    try:\n",
    "        subprocess.check_call(['git', 'checkout', '-b', branch])\n",
    "        print(f\"Create a new branch: {branch}\")\n",
    "    except:\n",
    "        subprocess.check_call(['git', 'checkout', branch])\n",
    "        print(f\"Checkout existing branch: {branch}\")\n",
    "    print(\"Add files to DVC\")\n",
    "    subprocess.check_call(['dvc', 'add', 'train/california_train.csv'])\n",
    "    subprocess.check_call(['dvc', 'add', 'validation/california_validation.csv'])\n",
    "    subprocess.check_call(['dvc', 'add', 'test/california_test.csv'])\n",
    "    subprocess.check_call(['git', 'add', '.'])\n",
    "    subprocess.check_call(['git', 'commit', '-m', f\"'add data for {branch}'\"])\n",
    "    print(\"Push data to DVC\")\n",
    "    subprocess.check_call(['dvc', 'push'])\n",
    "    print(\"Push dvc metadata to git\")\n",
    "    subprocess.check_call(['git', 'push', '--set-upstream', 'origin', branch, '--force'])\n",
    "    commit_hash = subprocess.check_output(['git', 'log', '--format=%H', '-n', '1']).decode(\"utf-8\").replace('\\n','')\n",
    "    #my_tracker.log_parameters({\"data_commit_hash\": commit_hash})\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    print(parser)\n",
    "    parser.add_argument(\"--train-test-split-ratio\", type=float, default=0.3)\n",
    "    parser.add_argument(\"--dvc-repo-url\", type=str, default=\"codecommit::eu-west-1://sagemaker-dvc-sample\")\n",
    "    parser.add_argument(\"--dvc-tag\", type=str, default=\"v1.0.0\")\n",
    "    parser.add_argument(\"--dvc-branch\", type=str, default=\"experiment-1\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    clone_dvc_git_repo(args.dvc_repo_url)\n",
    "    generate_train_validation_files(args.train_test_split_ratio)\n",
    "    sync_data_with_dvc(args.dvc_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "image = \"{}.dkr.ecr.{}.amazonaws.com/sagemaker-processing-dvc:latest\".format(account, region)\n",
    "\n",
    "script_processor = ScriptProcessor(command=['python3'],\n",
    "                image_uri=image,\n",
    "                role=role,\n",
    "                instance_count=1,\n",
    "                instance_type='ml.m5.xlarge')\n",
    "\n",
    "#ScriptProcessor to use a custom made image\n",
    "#https://docs.aws.amazon.com/sagemaker/latest/dg/processing-container-run-scripts.html\n",
    "\n",
    "experiment_config={\n",
    "    \"ExperimentName\": my_experiment.experiment_name,\n",
    "    \"TrialName\": my_first_trial.trial_name,\n",
    "    \"TrialComponentDisplayName\": \"CustomProcessing\"\n",
    "}\n",
    "\n",
    "script_processor.run(\n",
    "    code='preprocessing-experiment-2.py',\n",
    "    inputs=[ProcessingInput(source=s3_data_path, destination=\"/opt/ml/processing/input\")],\n",
    "    experiment_config=experiment_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "repo_name=\"sagemaker-dvc-sample\"\n",
    "cd \"${repo_name}\"\n",
    "\n",
    "git checkout -b dataset_v1.0.0\n",
    "\n",
    "dvc add dataset/test/california_test.csv\n",
    "dvc add dataset/validation/california_validation.csv\n",
    "dvc add dataset/train/california_train.csv\n",
    "\n",
    "git add .\n",
    "\n",
    "git commit -m 'add dev_dataset_1'\n",
    "\n",
    "dvc push\n",
    "git push --set-upstream origin dataset_v1.0.0\n",
    "\n",
    "git tag v1.0.0\n",
    "git push --tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using your Algorithm in Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an estimator and fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use DVC integration, pass a `dvc_repo_url` and `dvc_tag` as parameters when you create the Estimator object.\n",
    "\n",
    "We will train on the `v1.0.0` tag first.\n",
    "\n",
    "When doing `dvc pull`, this is the dataset structure:\n",
    "\n",
    "```\n",
    "dataset\n",
    "    |-- train\n",
    "    |   |-- california_train.csv\n",
    "    |-- test\n",
    "    |   |-- california_test.csv\n",
    "    |-- validation\n",
    "    |   |-- california_validation.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvc_repo_url = \"codecommit::{}://sagemaker-dvc-sample\".format(region)\n",
    "dvc_tag = \"experiment-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvc_repo_extended = \"https://git-codecommit.{}.amazonaws.com/v1/repos/sagemaker-dvc-sample\".format(region)\n",
    "\n",
    "with Tracker.create(display_name=\"DatasetLineage\") as tracker:\n",
    "    tracker.log_parameters(\n",
    "        {\n",
    "            \"dataset_git_tag\": dvc_tag,\n",
    "            \"dataset_git_repo\": dvc_repo_extended\n",
    "        }\n",
    "    )\n",
    "\n",
    "my_first_trial.add_trial_component(tracker.trial_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"{}.dkr.ecr.{}.amazonaws.com/sagemaker-catboost-dvc:latest\".format(account, region)\n",
    "\n",
    "metric_definitions = [{'Name': 'median-AE', 'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}]\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    metric_definitions=metric_definitions,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={\n",
    "            \"dvc-repo-url\": dvc_repo_url,\n",
    "            \"dvc-tag\": dvc_tag\n",
    "    },\n",
    ")\n",
    "\n",
    "experiment_config={\n",
    "    \"ExperimentName\": my_experiment.experiment_name,\n",
    "    \"TrialName\": my_first_trial.trial_name,\n",
    "    \"TrialComponentDisplayName\": \"Training\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-catboost-dvc-2022-03-08-14-30-06-951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-08 14:30:07 Starting - Starting the training job...\n",
      "2022-03-08 14:30:22 Starting - Preparing the instances for trainingProfilerReport-1646749806: InProgress\n",
      "......\n",
      "2022-03-08 14:31:27 Downloading - Downloading input data......\n",
      "2022-03-08 14:32:32 Training - Training image download completed. Training in progress.\u001b[34mReading hyperparameters data: /opt/ml/input/config/hyperparameters.json\u001b[0m\n",
      "\u001b[34mhyperparameters_data: {'dvc-repo-url': 'codecommit::eu-west-1://sagemaker-dvc-sample', 'dvc-tag': 'experiment-1'}\u001b[0m\n",
      "\u001b[34mConfigure git to pull authenticated from CodeCommit\u001b[0m\n",
      "\u001b[34mCloning repo: codecommit::eu-west-1://sagemaker-dvc-sample, git tag: experiment-1\u001b[0m\n",
      "\u001b[34mCloning into '/opt/ml/input/data'...\u001b[0m\n",
      "\u001b[34mremote: #015remote: Counting objects: 23#015remote: Counting objects: 23#015remote: Counting objects: 23, done.        \u001b[0m\n",
      "\u001b[34mRunning dvc pull command\u001b[0m\n",
      "\u001b[34mA       validation/california_validation.csv\u001b[0m\n",
      "\u001b[34mA       train/california_train.csv\u001b[0m\n",
      "\u001b[34mA       test/california_test.csv\u001b[0m\n",
      "\u001b[34m3 files added and 3 files fetched\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mFound train files: ['/opt/ml/input/data/dataset/train/california_train.csv']\u001b[0m\n",
      "\u001b[34mFound validation files: ['/opt/ml/input/data/dataset/validation/california_validation.csv']\u001b[0m\n",
      "\u001b[34mbuilding training and validation datasets\u001b[0m\n",
      "\u001b[34mvalidating model\u001b[0m\n",
      "\u001b[34mAE-at-10th-percentile: 0.18078711359801503\u001b[0m\n",
      "\u001b[34mAE-at-50th-percentile: 1.8861912081952994\u001b[0m\n",
      "\u001b[34mAE-at-90th-percentile: 4.491343631405186\u001b[0m\n",
      "\u001b[34msaving model file to /opt/ml/model/catboost-regressor-model.dump\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2022-03-08 14:32:54 Uploading - Uploading generated training model\n",
      "2022-03-08 14:32:54 Completed - Training job completed\n",
      "Training seconds: 87\n",
      "Billable seconds: 87\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(experiment_config=experiment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the logs above you can see those lines, indicating about the files pulled by dvc:\n",
    "\n",
    "```\n",
    "Running dvc pull command\n",
    "A       train/california_train.csv\n",
    "A       test/california_test.csv\n",
    "A       validation/california_validation.csv\n",
    "3 files added and 3 files fetched\n",
    "Starting the training.\n",
    "Found train files: ['/opt/ml/input/data/dataset/train/california_train.csv']\n",
    "Found validation files: ['/opt/ml/input/data/dataset/train/california_train.csv']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second version of the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data creation \n",
    "\n",
    "def split_dataframe(df, num=5):\n",
    "    chunks = [df.iloc[i:i+num] for i in range(0,df.shape[0], int(df.shape[0] / num))]\n",
    "    return chunks\n",
    "\n",
    "for index, chunk in enumerate(split_dataframe(pd.DataFrame(train))):\n",
    "    chunk.to_csv(f\"{base_dir}/train/california_train_{index + 1}.csv\", header=False, index=False)\n",
    "\n",
    "for index, chunk in enumerate(split_dataframe(pd.DataFrame(validation), 3)):\n",
    "    chunk.to_csv(f\"{base_dir}/validation/california_validation_{index + 1}.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "repo_name=\"sagemaker-dvc-sample\"\n",
    "cd \"${repo_name}\"\n",
    "\n",
    "git checkout -b dataset_v2.0.0\n",
    "\n",
    "dvc add dataset/test/california_test*.csv\n",
    "dvc add dataset/validation/california_validation*.csv\n",
    "dvc add dataset/train/california_train*.csv\n",
    "\n",
    "git add .\n",
    "\n",
    "git commit -m 'add dev_dataset_2'\n",
    "\n",
    "dvc push\n",
    "git push --set-upstream origin dataset_v2.0.0\n",
    "\n",
    "git tag v2.0.0\n",
    "git push --tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train on the `v2.0.0` tag.\n",
    "\n",
    "When doing `dvc pull`, this is the dataset structure:\n",
    "\n",
    "```\n",
    "dataset\n",
    "    |-- train\n",
    "    |   |-- california_train_1.csv\n",
    "    |   |-- california_train_2.csv\n",
    "    |   |-- california_train_3.csv\n",
    "    |   |-- california_train_4.csv\n",
    "    |   |-- california_train_5.csv\n",
    "    |-- test\n",
    "    |   |-- california_test.csv\n",
    "    |-- validation\n",
    "    |   |-- california_validation_1.csv\n",
    "    |   |-- california_validation_2.csv\n",
    "    |   |-- california_validation_3.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_trial_name = \"dvc-trial-v2\"\n",
    "\n",
    "try:\n",
    "    my_second_trial = Trial.load(trial_name=second_trial_name)\n",
    "    print(\"existing trial loaded\")\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        my_second_trial = Trial.create(\n",
    "            experiment_name=experiment_name,\n",
    "            trial_name=second_trial_name,\n",
    "        )\n",
    "        print(\"new trial created\")\n",
    "    else:\n",
    "        print(f\"Unexpected {ex}=, {type(ex)}\")\n",
    "        print(\"Dont go forward!\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvc_tag = \"v2.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracker.create(display_name=\"DatasetLineage\") as ptracker:\n",
    "    ptracker.log_parameters(\n",
    "        {\n",
    "            \"dataset_git_tag\": dvc_tag,\n",
    "            \"dataset_git_repo\": dvc_repo_extended\n",
    "        }\n",
    "    )\n",
    "\n",
    "my_second_trial.add_trial_component(ptracker.trial_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    metric_definitions=metric_definitions,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={\n",
    "            \"dvc-repo-url\": dvc_repo_url,\n",
    "            \"dvc-tag\": dvc_tag\n",
    "        },\n",
    ")\n",
    "\n",
    "experiment_config={\n",
    "    \"ExperimentName\": my_experiment.experiment_name,\n",
    "    \"TrialName\": my_second_trial.trial_name,\n",
    "    \"TrialComponentDisplayName\": \"Training\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(experiment_config=experiment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the logs above you can see those lines, indicating about the files pulled by dvc:\n",
    "\n",
    "```\n",
    "Running dvc pull command\n",
    "A       validation/california_validation_2.csv\n",
    "A       validation/california_validation_1.csv\n",
    "A       validation/california_validation_3.csv\n",
    "A       train/california_train_4.csv\n",
    "A       train/california_train_5.csv\n",
    "A       train/california_train_2.csv\n",
    "A       train/california_train_3.csv\n",
    "A       train/california_train_1.csv\n",
    "A       test/california_test.csv\n",
    "9 files added and 9 files fetched\n",
    "Starting the training.\n",
    "Found train files: ['/opt/ml/input/data/dataset/train/california_train_2.csv', '/opt/ml/input/data/dataset/train/california_train_5.csv', '/opt/ml/input/data/dataset/train/california_train_4.csv', '/opt/ml/input/data/dataset/train/california_train_1.csv', '/opt/ml/input/data/dataset/train/california_train_3.csv']\n",
    "Found validation files: ['/opt/ml/input/data/dataset/validation/california_validation_2.csv', '/opt/ml/input/data/dataset/validation/california_validation_1.csv', '/opt/ml/input/data/dataset/validation/california_validation_3.csv']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "predictor = estimator.deploy(1, \"ml.t2.medium\", serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke endpoint with the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predictor.predict(test).decode('utf-8')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the Endpoint\n",
    "\n",
    "Make sure to delete the endpoint to avoid un-expected costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Delete the Experiment, and all Trails, TrialComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_experiment.delete_all(action=\"--force\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the AWS CodeCommit repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws codecommit delete-repository --repository-name sagemaker-dvc-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python [conda env: dvc] (conda-env-dvc-kernel/latest)",
   "language": "python",
   "name": "conda-env-dvc-py__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:583558296381:image/conda-env-dvc-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
